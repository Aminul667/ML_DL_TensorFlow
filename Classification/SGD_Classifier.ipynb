{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np \n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rahat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\datasets\\_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.3.2.\n"
     ]
    }
   ],
   "source": [
    "print('scikit-learn version: {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rahat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:528: RuntimeWarning: invalid value encountered in cast\n",
      "  fill_value = lib.item_from_zerodim(np.array(np.nan).astype(dtype))\n"
     ]
    }
   ],
   "source": [
    "mnist.target = mnist.target.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist['data'].to_numpy(), mnist['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[426]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.  13.  24.  17.  19.  13.   0.   0.   0.   0.   0.   0.\n",
      "    0.   0.   9.  13.  24.  45. 138. 138.  13.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0. 159. 252. 227. 236. 211. 162. 161. 161. 109. 161. 151.\n",
      "  120. 161. 194. 211. 253. 252. 252. 252.  96.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0. 253. 252. 252. 252. 252. 253. 252. 252. 252. 252. 253.\n",
      "  252. 252. 252. 252. 253. 252. 252. 252. 168.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0. 253. 252. 252. 252. 252. 253. 252. 252. 252. 252. 253.\n",
      "  252. 252. 252. 252. 253. 252. 252. 252. 157.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0. 148. 252. 252. 252. 252. 253. 252. 252. 252. 252. 253.\n",
      "  252. 252. 252. 252. 253. 252. 252. 252. 137.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.  74. 116.  63. 168. 231. 230. 230. 178. 230. 179.\n",
      "  230. 199. 229. 253. 255. 253. 253. 245.  73.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.  13. 215. 252. 253. 252. 252.  87.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "    0.  70. 252. 252. 253. 252. 170.  13.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   17. 188. 252. 252. 253. 235.  44.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   99. 252. 252. 252. 190. 113.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  110. 253. 253. 253. 231.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  36.\n",
      "  219. 252. 252. 252. 230.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 138.\n",
      "  252. 252. 252. 221.  63.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 138.\n",
      "  252. 252. 252. 137.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 138.\n",
      "  252. 252. 252. 137.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139.\n",
      "  253. 253. 253. 137.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 212.\n",
      "  252. 252. 252. 137.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 169.\n",
      "  252. 252. 195.  48.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  88.\n",
      "  202. 128.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   11.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "digit = X[426]\n",
    "digit = digit.reshape(28, 28)\n",
    "print(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:60000]\n",
    "X_test = X[60000:]\n",
    "\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Sensitivity\n",
    "\n",
    "By shuffling the data, the model is exposed to different patterns in each epoch, which helps prevent it from overfitting to specific patterns in the training data. In other words, shuffling data helps the model to generalize better to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train = X_train[shuffle_index]\n",
    "y_train = y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Classification and SGD Classifier\n",
    "#### Binary Classification\n",
    "Binary Classification is a type of machine learning algorithm used to classify data into one of two categories. It predicts a binary outcome, where the result can either be positive or negative. For example, binary classification can be used to predict if a customer will buy a product or not, or if an email is spam or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mathematical Formulas\n",
    "\n",
    "$$\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "  x_1 \\\\\n",
    "  x_2 \\\\\n",
    "  \\vdots \\\\\n",
    "  x_n \\\\\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "y = \n",
    "\\begin{bmatrix}\n",
    "  y_1 \\\\\n",
    "  y_2 \\\\\n",
    "  \\vdots \\\\\n",
    "  y_n \\\\\n",
    "\\end{bmatrix};\n",
    "y_n \\in \\{0, 1\\}\n",
    "\n",
    "$$\n",
    "$$\n",
    "f(x) = w^TX + b \\quad \\text{where} \\quad \n",
    "f(x) =\n",
    "\\begin{cases}\n",
    "  +1,\\quad \\text{$f(x) > 0$}\\\\\n",
    "  -1 \\quad \\text{else}\n",
    "\\end{cases}\n",
    "$$\n",
    "SGD minimize: \n",
    "$$\n",
    "\\epsilon (w, b) = \\frac{1}{n}\\sum_{i=1}^n L(y_i, f(x_i)) + \\alpha R(w)\n",
    "$$\n",
    "where $L(y_i, f(x_i))$ is loss function, $R(w)$ is a regularization term which penalizes the model complexity and $\\alpha is a certain hyper parameter$.\n",
    "\n",
    "Loss Function:\n",
    "1. Least Square: $[y_i - f(x_i)]^2$\n",
    "2. Logistic Regression:\n",
    "$$\n",
    "\\begin{cases}\n",
    "  -\\log(f(x_i)),\\quad \\text{if $y_i = 1$}\\\\\n",
    "  -\\log(1 - f(x_i)) \\quad \\text{else}\n",
    "\\end{cases}\n",
    "$$\n",
    "3. Hinge: $\\max[0, 1 - y_if(x_i)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_6 = y_train == 6\n",
    "y_test_6 = y_train == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
